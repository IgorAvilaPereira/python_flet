# python_flet

## Criando Projeto e o virtualenv

```sh
mkdir first-flet-app
cd first-flet-app
python3 -m venv .venv
source .venv/bin/activate
```

## Instalando o Flet

```sh
pip install flet[all]
```

## Criando um projeto

```sh
flet create
```

## Exemplo

```python
import flet as ft

def main(page: ft.Page):
    page.title = "Flet counter example"
    page.vertical_alignment = ft.MainAxisAlignment.CENTER

    txt_number = ft.TextField(value="0", text_align=ft.TextAlign.RIGHT, width=100)

    def minus_click(e):
        txt_number.value = str(int(txt_number.value) - 1)
        page.update()

    def plus_click(e):
        txt_number.value = str(int(txt_number.value) + 1)
        page.update()

    page.add(
        ft.Row(
            [
                ft.IconButton(ft.Icons.REMOVE, on_click=minus_click),
                txt_number,
                ft.IconButton(ft.Icons.ADD, on_click=plus_click),
            ],
            alignment=ft.MainAxisAlignment.CENTER,
        )
    )

ft.app(main)
```

## Rodando

```sh
flet run [script]
```

### Web

```sh
flet run --web [script]
```

## DiretÃ³rio - Projeto PadrÃ£o Flet

```
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ assets
â”‚   â”‚   â””â”€â”€ icon.png
â”‚   â””â”€â”€ main.py
â””â”€â”€ storage
    â”œâ”€â”€ data
    â””â”€â”€ temp
```

### Desktop

```sh
flet run
```

### Web

```sh
flet run --web
```

### App Android

https://play.google.com/store/apps/details?id=com.appveyor.flet

```sh
flet run --android
```

### App IOs

https://apps.apple.com/app/flet/id1624979699

```sh
flet run --ios
```

## Build

* https://flet.dev/docs/publish/android

```sh
sudo snap install flutter --classic
sudo snap install android-studio --classic
flet build apk
```

* https://flet.dev/docs/publish/ios

* https://flet.dev/docs/publish/linux

* https://flet.dev/docs/publish/windows

* https://flet.dev/docs/publish/web

### Sqlite

https://docs.python.org/pt-br/3.9/library/sqlite3.html

```sh
sqlite3 my_database.db
```

```sql
CREATE TABLE products (
    product_id INTEGER PRIMARY KEY AUTOINCREMENT,
    product_name TEXT NOT NULL,
    price REAL
);
```

```python
    import sqlite3

    with sqlite3.connect('my_database.db') as conn:
        cursor = conn.cursor()
        cursor.execute("INSERT INTO users (name, email) VALUES (?, ?)", ("Bob", "bob@example.com"))
        conn.commit()

    with sqlite3.connect('my_database.db') as conn:
        cursor.execute("SELECT * FROM users")
        rows = cursor.fetchall()
        for row in rows:
            print(row)
    
```

### API Pokemon

https://github.com/PokeAPI/pokebase

### OFF-TOPIC:

https://console.groq.com/docs/quickstart
```sh
pip install groq
```

<!--
#### ðŸ” Modelos bons gratuitos


| Modelo                          | Tamanho / ParÃ¢metros / Bits / QuantizaÃ§Ã£o                                                           | Pontos fortes                                                                                                                                          | RestriÃ§Ãµes / O que vocÃª precisa considerar                                                                                            |
| ------------------------------- | --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------- |
| **Llama-3 (8B ou 70B)** da Meta | VersÃ£o open-source, com quantizaÃ§Ãµes disponÃ­veis (ex: GGUF, bits menores). ([GIGAZINE][1])          | Ã‰ um dos mais recentes da Meta; bom equilÃ­brio entre desempenho e custo computacional, especialmente o de 8 bilhÃµes de parÃ¢metros. Boa para uso geral. | O modelo de 70B exige bastante memÃ³ria; usar quantizaÃ§Ãµes Ã© quase obrigatÃ³rio para rodar localmente com bom desempenho. ([Reddit][2]) |
| **Llama-2 (7B / 13B / 70B)**    | Modelos bem conhecidos, versÃµes base e ajustadas. VersÃµes em GGUF tambÃ©m disponÃ­veis. ([MyGGUF][3]) | EstÃ¡vel, bem estudado, muitos recursos e bibliotecas/pacotes jÃ¡ suportam. Boa escolha se quiser compatibilidade e documentaÃ§Ã£o.                        | TambÃ©m o de maior porte consome muito; para tarefas simples, talvez o 7B jÃ¡ seja suficiente.                                          |
| **Mistral-7B (Instruct)**       | Um modelo â€œmenorâ€, bom custo computacional. ([localaimaster.com][4])                                | Excelente para criatividade / geraÃ§Ã£o de texto quando nÃ£o se precisa de algo extremamente grande. Carrega mais rÃ¡pido, uso de RAM menor.               | Pode perder em tarefas que requeiram muito contexto ou â€œraciocÃ­nioâ€ mais pesado comparado aos maiores.                                |
| **TinyLlama**                   | \~1.1B parÃ¢metros. ([arXiv][5])                                                                     | Muito leve, roda fÃ¡cil mesmo em mÃ¡quinas modestas; bom para protÃ³tipos, testagens rÃ¡pidas, tarefas simples.                                            | Com desempenho menor, respostas menos refinadas se comparar com modelos grandes. NÃ£o Ã© ideal para uso â€œpesadoâ€.                       |



---

#### Llama

```sh
python3 -m venv .venv
source .venv/bin/activate
pip install llama-cpp-python
```

```python
from llama_cpp import Llama

# Carregue um modelo LLaMA (precisa ter o arquivo .gguf baixado antes)
llm = Llama(model_path="models/llama-2-7b-chat.Q4_K_M.gguf")

# Fazendo uma pergunta ao modelo
output = llm(
    "Explique em poucas palavras o que Ã© aprendizado de mÃ¡quina.",
    max_tokens=100,
    temperature=0.7,
)

print(output["choices"][0]["text"])
```


python3 Llama.py


